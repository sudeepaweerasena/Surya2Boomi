{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Solar Wind Speed Forecasting Tutorial for Beginners üåûüí®\n",
        "\n",
        "This notebook will guide you through running Solar Wind speed forecasting using the Surya model. \n",
        "\n",
        "## What you'll learn:\n",
        "- How to load a pre-trained model for solar wind speed prediction\n",
        "- How to run inference on solar data\n",
        "- How to interpret regression forecasting results\n",
        "- Understanding continuous predictions vs binary classification\n",
        "\n",
        "## Prerequisites:\n",
        "- Make sure you're in the correct directory: `downstream_examples/solar_wind_forcasting/`\n",
        "- Ensure all required packages are installed (torch, yaml, matplotlib, numpy, etc.)\n",
        "\n",
        "Let's get started! üöÄ\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/nobackupnfs1/sroy14/rohit/surya_worktree/main/.venv/lib64/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ All imports successful!\n",
            "PyTorch version: 2.8.0+cu126\n",
            "CUDA available: False\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import yaml\n",
        "import numpy as np\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "# Import functions from our inference script\n",
        "from infer import (\n",
        "    run_inference,\n",
        ")\n",
        "\n",
        "# Import from surya\n",
        "from surya.utils.data import build_scalers\n",
        "from surya.utils.distributed import set_global_seed\n",
        "\n",
        "print(\"‚úÖ All imports successful!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 2: Download Pre-trained Model Weights\n",
        "The model weights will be downloaded automatically from Hugging Face.\n",
        "This may take a few minutes the first time you run the code.\n",
        "\n",
        "For downloading the dataset (if not already present locally):\n",
        "- If the cell below fails, try running the provided shell script directly in the terminal.\n",
        "- Sometimes the download may fail due to network or server issues‚Äîif that happens, simply re-run the script a few times until it completes successfully."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==> Checking assets directory at: /nobackupnfs1/sroy14/rohit/surya_worktree/main/downstream_examples/solar_wind_forcasting/assets\n",
            "==> Downloading dataset 'nasa-ibm-ai4science/Surya-bench-solarwind' to '/nobackupnfs1/sroy14/rohit/surya_worktree/main/downstream_examples/solar_wind_forcasting/assets/Surya-bench-solarwind'\n",
            "Fetching 7 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7/7 [00:00<00:00, 426.70it/s]\n",
            "/nobackupnfs1/sroy14/rohit/surya_worktree/main/downstream_examples/solar_wind_forcasting/assets/Surya-bench-solarwind\n",
            "Fetching 1 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:00<00:00, 106.09it/s]\n",
            "/nobackupnfs1/sroy14/rohit/surya_worktree/main/downstream_examples/solar_wind_forcasting/assets\n",
            "Fetching 19 files: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 19/19 [00:00<00:00, 456.41it/s]\n",
            "/nobackupnfs1/sroy14/rohit/surya_worktree/main/downstream_examples/solar_wind_forcasting/assets\n",
            "‚úì Done. Files are in: /nobackupnfs1/sroy14/rohit/surya_worktree/main/downstream_examples/solar_wind_forcasting/assets/Surya-bench-solarwind\n"
          ]
        }
      ],
      "source": [
        "!sh download_data.sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 3: Set Up Configuration\n",
        "\n",
        "We need to load the configuration file that contains all the model and data parameters. Make sure you have a `config.yaml` file in your current directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìã Loading configuration...\n",
            "‚úÖ Configuration loaded successfully!\n",
            "Model type: spectformer\n",
            "Data precision: torch.float32\n"
          ]
        }
      ],
      "source": [
        "# Configuration paths - modify these if your files are in different locations\n",
        "config_path = \"./config_infer.yaml\"\n",
        "checkpoint_path = \"./assets/solar_wind_weights.pth\"\n",
        "output_dir = \"./inference_results\"\n",
        "\n",
        "# Set global seed for reproducibility\n",
        "set_global_seed(42)\n",
        "\n",
        "# Load configuration\n",
        "print(\"üìã Loading configuration...\")\n",
        "try:\n",
        "    config = yaml.safe_load(open(config_path, \"r\"))\n",
        "    config[\"data\"][\"scalers\"] = yaml.safe_load(open(config[\"data\"][\"scalers_path\"], \"r\"))\n",
        "    print(\"‚úÖ Configuration loaded successfully!\")\n",
        "except FileNotFoundError as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n",
        "    print(\"Make sure config.yaml exists in your current directory\")\n",
        "    raise\n",
        "\n",
        "# Set data type (float precision)\n",
        "if config[\"dtype\"] == \"float16\":\n",
        "    config[\"dtype\"] = torch.float16\n",
        "elif config[\"dtype\"] == \"bfloat16\":\n",
        "    config[\"dtype\"] = torch.bfloat16\n",
        "elif config[\"dtype\"] == \"float32\":\n",
        "    config[\"dtype\"] = torch.float32\n",
        "else:\n",
        "    raise NotImplementedError(\"Please choose from [float16,bfloat16,float32]\")\n",
        "\n",
        "print(f\"Model type: {config['model']['model_type']}\")\n",
        "print(f\"Data precision: {config['dtype']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 4: Set Up Device (GPU/CPU)\n",
        "\n",
        "Let's determine whether to use GPU or CPU for inference. GPU is much faster if available!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üêå Using CPU (this will be slower)\n",
            "üí° Tip: Consider using a machine with GPU for faster inference\n"
          ]
        }
      ],
      "source": [
        "# Set device - automatically use GPU if available, otherwise CPU\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f\"üöÄ Using GPU: {torch.cuda.get_device_name()}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"üêå Using CPU (this will be slower)\")\n",
        "    print(\"üí° Tip: Consider using a machine with GPU for faster inference\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Step 5: Run Solar Wind Speed Forecasting (Easy Method)\n",
        "\n",
        "This is the simplest way to run inference. The `run_inference` function handles everything for you and will show wind speed predictions vs ground truth!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üî¨ Starting solar wind speed forecasting inference...\n",
            "Loading model from ./assets/solar_wind_weights.pth\n",
            "Initializing HelioSpectformer1D.\n",
            "Loading pretrained model from ../../data/Surya-1.0/surya.366m.v1.pt.\n",
            "Applying PEFT LoRA with configuration: {'r': 64, 'lora_alpha': 32, 'target_modules': ['q_proj', 'v_proj', 'k_proj', 'out_proj', 'fc1', 'fc2'], 'lora_dropout': 0.1, 'bias': 'none'}\n",
            "trainable params: 8,192,000 || all params: 367,501,313 || trainable%: 2.23%\n",
            "Timedelta 4 days\n",
            "Scalers are not a list of torch tensors, float, int or np.ndarray. What are you feeding in?\n",
            "Dataset size: 3\n",
            "Running inference on 3 samples\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/nobackupnfs1/sroy14/rohit/surya_worktree/main/.venv/lib64/python3.11/site-packages/torch/utils/data/dataloader.py:666: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running inference on 0th sample\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/nobackupnfs1/sroy14/rohit/surya_worktree/main/.venv/lib64/python3.11/site-packages/torch/amp/autocast_mode.py:283: UserWarning: In CPU autocast, but the target dtype is not supported. Disabling autocast.\n",
            "CPU Autocast only supports dtype of torch.bfloat16, torch.float16 currently.\n",
            "  warnings.warn(error_message)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "==========================================================================================\n",
            "Time Input           | Time Target          | Prediction (km/s)    | Ground Truth (km/s) \n",
            "------------------------------------------------------------------------------------------\n",
            "2011-01-20T01:00     | 2011-01-20T02:00     | 393.63               | 344.00              \n",
            "==========================================================================================\n",
            "Running inference on 1th sample\n",
            "\n",
            "==========================================================================================\n",
            "Time Input           | Time Target          | Prediction (km/s)    | Ground Truth (km/s) \n",
            "------------------------------------------------------------------------------------------\n",
            "2019-01-23T02:00     | 2019-01-23T03:00     | 391.95               | 433.00              \n",
            "==========================================================================================\n",
            "Running inference on 2th sample\n",
            "\n",
            "==========================================================================================\n",
            "Time Input           | Time Target          | Prediction (km/s)    | Ground Truth (km/s) \n",
            "------------------------------------------------------------------------------------------\n",
            "2011-01-20T02:00     | 2011-01-20T03:00     | 383.07               | 351.00              \n",
            "==========================================================================================\n",
            "\n",
            "==========================================================================================\n",
            "SUMMARY STATISTICS\n",
            "==========================================================================================\n",
            "Metric                    | Value               \n",
            "------------------------------------------------------------------------------------------\n",
            "Mean Absolute Error       | 40.9170             \n",
            "Root Mean Square Error    | 41.5408             \n",
            "R¬≤ Score                  | -0.0569             \n",
            "Number of Samples         | 3                   \n",
            "==========================================================================================\n",
            "üéâ Solar wind speed forecasting completed successfully!\n"
          ]
        }
      ],
      "source": [
        "# Parameters for inference\n",
        "data_type = \"test\"  # or \"valid\" - which dataset to use\n",
        "num_samples = 3  # Number of samples to process and analyze\n",
        "device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "print(\"üî¨ Starting solar wind speed forecasting inference...\")\n",
        "# Run the complete inference pipeline\n",
        "try:\n",
        "    run_inference(\n",
        "        config=config,\n",
        "        checkpoint_path=checkpoint_path,\n",
        "        output_dir=output_dir,\n",
        "        device=device,\n",
        "        data_type=data_type,\n",
        "        num_samples=num_samples,\n",
        "        device_type=device_type\n",
        "    )\n",
        "    print(\"üéâ Solar wind speed forecasting completed successfully!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error during inference: {e}\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Understanding the Results üìä\n",
        "\n",
        "### What you're seeing:\n",
        "- **Time Input**: The timestamp of the input solar observations\n",
        "- **Time Target**: The timestamp for which we're making the wind speed prediction\n",
        "- **Prediction (km/s)**: The model's predicted solar wind speed in kilometers per second\n",
        "- **Ground Truth (km/s)**: The actual observed wind speed\n",
        "\n",
        "### Key Metrics Explained:\n",
        "1. **Mean Absolute Error (MAE)**: Average absolute difference between predictions and actual values (lower is better)\n",
        "2. **Root Mean Square Error (RMSE)**: Square root of average squared differences (penalizes larger errors more)\n",
        "3. **R¬≤ Score**: Coefficient of determination (closer to 1.0 means better predictions, can be negative for very poor models)\n",
        "\n",
        "### Tips for interpretation:\n",
        "1. **Good predictions**: Predicted values close to ground truth values\n",
        "2. **Time difference**: Shows how far ahead the model is forecasting (typically 4 days)\n",
        "3. **Wind speed range**: Typical solar wind speeds are 250-800 km/s\n",
        "4. **Solar storms**: Very high speeds (>600 km/s) often indicate coronal mass ejections\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Summary üéØ\n",
        "\n",
        "Congratulations! You've successfully run solar wind speed forecasting using the Surya model. \n",
        "\n",
        "### What you accomplished:\n",
        "‚úÖ Downloaded pre-trained model weights  \n",
        "‚úÖ Loaded and configured the regression model  \n",
        "‚úÖ Ran inference on solar data  \n",
        "‚úÖ Generated wind speed predictions with timestamps  \n",
        "‚úÖ Compared predictions with ground truth measurements  \n",
        "‚úÖ Calculated regression metrics (MAE, RMSE, R¬≤)  \n",
        "\n",
        "### Understanding Solar Wind Forecasting:\n",
        "- **Regression Task**: Predicts continuous wind speed values (not binary yes/no)\n",
        "- **4-Day Forecast**: Uses current solar observations to predict wind speed 4 days ahead\n",
        "- **Practical Applications**: Space weather forecasting, satellite protection, power grid management\n",
        "- **Challenges**: Solar wind is inherently chaotic and difficult to predict with perfect accuracy\n",
        "\n",
        "Happy solar wind forecasting! üåûüí®üõ∞Ô∏è‚ú®\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
